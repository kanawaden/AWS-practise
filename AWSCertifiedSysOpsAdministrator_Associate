AutoScaling
- AutoScaling will throw an error when there is conflict in the schedule of 2 seperate autoscaling process. Error is thrown during configuration of the 2nd process itself and it will not allow to save 2nd process.
- As per Autoscaling, a user can schedule an action upto a month in the future.
- Autoscaling might suspend the processes for Auto Scaling groups that repeatedly fails to launch instances. This is known as an administrative suspension and most commonly applies to Auto Scaling groups that has been trying to launch instances for over 24 hours but have not succeeded in launching any instances.
- Autoscaling enables you to suspend and then resume one or more of the Autoscaling processes in ASG. This can be very useful when you want to investigate the configuration problem or other issue with your web application and then make changes into your application without triggering autoscaling process.
- The CLI command update-auto-scaling-group can be used to combine 2 groups.
- By default, basic monitoring is enabled when you create the launch configuration using the AWS Management Console.
- By default, detailed monitoring is enabled when  you create the launch configuration using AWS CLI or API.
- To terminate an instance using the CLI you need to use the terminate-instance-in-auto-scaling-group command. In this command, the user can specify the instance id which needs to be deleted. They need to mention the --no-should-decrement-desired-capacity option so that Autoscaling will launch instances with the new AMI configuration.
- Once can change the status of an instance using Autoscaling commands. The command used here would be set-instance-health.
- If you suspend AddToLoadBalancer, Auto Scaling launches the instances but does not add them to the laod balancer or target group. If you resume the AddToLoadBalancer process, Auto Scaling resumes adding instances to the load balancer or target group when they are launched. However, Auto Scaling does not add the instances that were launched while this process was suspended. You must register those instances manually.

Load Balancer
- To ensure that a classic load balancer stops sending requests to instances that are deregistered or unhealthy, while keeping the existing connection open, use connection draining. This enables load balancer to complete in-flight requests made to the instances that are deregistered or unhealthy.
- When you enable connection draining, you can specify the maximum time for the load balancer to keep the connection live before reporting the instance as deregistered. The maximum timeout value can be set between 1 to 3600 secs(1 hour).
- Default connection draining time is 300 seconds.
- Deleting the load balancer will not affect registered targets. Instances will keep on running even after elb deletion.
- Predefined security policy: SSL Protocols, SSL Options and SSL Ciphers.
- Format of ELB access log file: bucket[/prefix]/AWSLogs/aws-account-id/elasticloadbalancing/region/yyyy/mm/dd/aws-account-id_elasticloadbalancing_region_load-balancer-id_end-time_ip-address_random-string.log.gz
- One can add more AZ to the existing load balancer. From console, select ELB and go to instances tab to add AZ. From CLI, use enable-availability-zones-for-load-balancer command to add an Availability Zone.


SNS
- Available Endpoints: HTTP, HTTPS, Email, Email-JSON, Amazon SQS, Application AWS Lambda, SMS

IAM
- AWS login URL: https://999988887777.signin.aws.amazon.com/console/
- A group cannot be a part of another group.
- A groups can be granted permissions using access control policies.
- The best practise for IAM is to create roles which has specific access to an AWS service and then give the user permission to the AWS service via the role.
- If its a combination of various services, there will be large number of groups and might not be maintainable. Hence, role for service and ability for user to take up the role and ability to change roles would be much cleaner.
- You can actually use a Deny condition which will not allow the person to log in from outside.(look for Condition: NotIpAddress)

EBS
- Default limit of EBS snapshot is 10,000.
- EBS snapshots - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html
- New EBS volumes receive their maximum performace the moment that they are available and do not require initialization (formerly known as pre-warming). However, storage blocks on volumes that were restored from snapshots must be initialized (pulled down from Amazon S3 and written to the volume) before you can access the block. This preliminary action takes time and can cause a significant increase in the latency of an I/O operation the first time each block is accessed.
- Each instance that you launch has an associated root device volume, either an Amazon EBS volume or an instance store volume. You can use block device mapping to specify additional EBS volumes or instance store volumes to attach to an instance when it's launched.
- Amazon EBS encryption offers a simple encryption solution for your EBS volumes without the need to build, maintain, and secure your own key management infrastructure. When you create an encrypted EBS volume and attach it to a supported instance type, the following types of data are encrypted:
  => Data at rest inside the volume
  => All data moving between the volume and the instance
  => All snapshots created from the volume
  => All volumes created from those snapshots

EC2
- AWS Tags enables you to categorise your AWS resources in different ways. As per AWS below are the restrictions on tags - 
    => Max no of tags per resource is 50.
    => Max key length is 127 unicode chars in UTF-8
    => Max value length is 255 unicode chars in UTF-8
    => Tags keys and values are case sensitive.
    => Do not use AWS: prefix in your tag names or values because it is reserved for AWS use.  
- When you try to delete a subnet which has instances it will not allow to delete it.
- For EC2 classic, the Elastic IP is disassociated from the instance when you stop it.
- You need to ensure you are entering right user name if you get the error "Host Key not found."
- A bastion host is a special purpose computer on a network specifically designed and configured to withstand attacks. The computer generally hosts a single application, for example a proxy server, and all other services are removed or limited to reduce the threat to the computer.
  In AWS, A bastion host is kept on a public subnet. Users log on to the bastion host via SSH or RDP and then use that session to manage other hosts in the private subnets.
  You can have a bastion host running in multiple AZ, but the recommendation is to have one running in each AZ. Hence you need to make sure that the Autoscaling group is set to a maz-size of one.
- An instance reboot is equivalent to an operating system reboot. In most cases, it takes only a few minutes to reboot your instance, it remains on the same physical host, so your instance keeps its public DNS name (IPv4), private IPv4 address, IPv6 address (if applicable), and any data on its instance store volumes.
- While creating AMI, ensure that you have following credentials:
  => Your Account ID.
  => An X.509 certificate and corresponding private key.
  => Your AWS account access key ID and secret access key.
- For each instance there is a property called State transition reason. This will show the user the reason as to why an EC2 instance would have been terminated.
- When EC2 instance fails to launch. 
- You can prevent an instance from being terminated accidentally by someone using the AWS Management Console, the CLI, and the API. The feature is available for both Amazon EC2 instance store-backed and Amazon EBS-backed instances. Each instance has a DisableApiTermination attribute with the default value of false (the instance can be terminated through Amazon EC2). You can modify this instance attribute while the instance is running or stopped (in the case of Amazon EBS-backed instances).
- For Windows instances, the instance console output displays the last three system event log errors.
- A placement group is a logical grouping of instances within a single AZ. Placement groups are recommended for applications that benefit from low network latency, high network throughput or both.

S3
- Bucket policy and user policy are two of the access policy options available for you to grant permission to your Amazon S3 resources. Both uses JSON-based access policy language.
- buckets ACL permission
  => Everyone
  => Any Authenticated AWS user
  => Log Delivery
  => Me
- S3 Analytics (Storage Class Analysis) helps you to analyze storage access patterns and transition the right data to the right storage class. This new S3 Analytics feature automatically identifies infrequest access patterns to help you transition storage to Standard-IA.
- S3 Object Tags are keyvalue pairs applied to S3 objects which can be created, updated or deleted at any time during the lifetime of the object. With these, you'll have the ability to create Identity and Access Management (IAM) policies, setup S3 lifecycle policies, and customize storage metrics. These object tags can then manage transitions between storage classes and expire objects in the background.
- S3 Inventory provides a scheduled alternative to Amazon S3's synchronous List API. You can configure S3 Inventory to provide a CSV or ORC file output of your objects and their corresponding metadata on a daily basis for an S3 bucket or prefix. You can simplify and speed up business workflows and big data jobs with S3 Inventory. You can use S3 inventory to verify encryption and replication status of your objects to meet business, compliance, and regulatory needs.
- S3 Multipart upload advantages:
  => Improved throughput - you can upload parts in parallel to improve throughput.
  => Quick recovery from any network issues - smaller part size minimized the impact of restarting a failed upload due to network error.
  => Pause and resume object uploads - you can upload object parts over time. Once you initiate a multipart upload there is no expirey; you must explicitly complete or abort the multipart upload.
  => Begin an upload before you know the final object size - you can upload an object as you are creating it.
- Bucket policies are limited to 20KB in size.
- Access Policy Language Overview
  Common Elements in an Access Policy
  => Resources: Buckets and objects are the Amazon S3 resources for which you can allow or deny permissions. In a policy, you use the Amazon Resource Name (ARN) to identify the resource.
  => Actions: For each resource, Amazon S3 supports a set of operations.
  => Effect: What the effect will be when the user requests the specific action - This can be either allow or deny.
  => Principal: The account or user who is allowed access to the actions and resources in the statement. In a bucket policy, the principal is the user, account, service or other entity who is the recipient of this permission.
  
Glacier
- Objects archived to Amazon Glacier are not accessible in real-time. You must first initiate a restore request and then wait until a temporary copy of the object is available for the duration (number of days) that you specify in the request.
- After you receive a temporary copy of the restored object, the object's storage class remains GLACIER (a GET or HEAD request will return GLACIER as the storage class). Note that when you restore an archive you pay for both the archive (GLACIER rate) and a copy you restored temporarily (RRS rate). 


CloudFormation
- You can use WaitCondition for situation like following:
  => To coordinate the stack resource creation with configuration actions that are external to the stack creation.
  => To track the status of configuration process.
- Elements of CloudFormation template (templates are JSON or YAML formatted text files)
  => An optional list of template parameters (input values supplied at stack creation time)
  => An optional list of output values (e.g. the complete URL to a web application)
  => An optional list of data tables used to lookup static configuration values (e.g AMI names)
  => The list of AWS resources and their conf value
  => A template file format version number
- By default, the "automatic rollback on error" feature is enabled.

VPC
- Go through CIDR properly.
- When you design a web server and db server, the security group must be defined so that the webserver can talk to db server whereas while communicating through subnets you need to define network ACL.
- Elastic Network Interface is a logical networking component in a VPC that represents a virtual network card.
- An Elastic IP address is a static IPv4 address designed for dynamic cloud computing. An Elastic IP address is associated with your AWS acount. With an Elastic IP address, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account.

Route53
- Go through all the Routing policies
- If your application is hosted on Amazon EC2 instances in multiple Amazon EC2 regions, you can reduce latency for your users by serving their requests from the Amazon EC2 region for which network latency is lowest. Amazon Route 53 latency based routing lets you use DNS to route user requests to the Amazon EC2 region that will give your users the fastest response. 
  The Evaluate Target health check will ensure availability. If any one of the regions fails, since the evaluate target is set to true, the requests will be sent to another region.
- 

RDS
- In a multi AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. The primary instance is synchronously replicated across AZ to a standby replica to provide data redundancy, eliminate IO freezes and minimizes latency spikes during system backups.
  As per AWS below are the best practices for multiAZ:
  => For production workloads, we recommend you use Provisioned IOPS and DB instance classes (m1.large and larger) that are optimized for provisioned IOPS for fast consistent performance.
  => Also if backups are scheduled during working hours, then I/O can be suspended and increase the latency of the DB, hence it is better to schedule outside office hours.
- By default AWS rotates the logs so its better to store it in database to ensure you archieve all the logs and you can then have the ability to find the errors by date.
- If you want to have an encrypted database storage option, you need to store them on EBS volumes which can be encrypted.
- Event Subscription Categories for RDS has below option: Creation, Deletion, Notification and Restoration.


SQS
- newly created queue structure : http://sqs.<aws-region>.amazonaws.com/<accountid>/<queue-name>
  for eg : http://sqs.us-east-1.amazonaws.com/123456123456/myqueue
- You can configure the amazon SQS message retention period to a value between 1 min to 14 days (default is 4 days). Once the message retention limit is reached, messages are automatically deleted.
- AWS reserve the right to delete a queue without notification if one of the following actions hasn't been performed on it for 30 consecutive days: SendMessage, ReceiveMessage, DeleteMessage, GetQueueAttributes, AddPermission and RemovePermission.
- When you delete a queue which contains messages. It will just prompt a message showing there are messages in a queue but after which it will just delete the queue.
-

Billing
- Billing reports provide information about your usage of AWS resources and estimated costs for that usage. You can have AWS generated billing reports that break down your estimated costs in different ways:
  => By the hour, day or month.
  => By each account in your organisation.
  => By product or product resource.
  => By tags that you define yourself.
- Cost Explorer helps to get more details on spendings.
- A tag is a label that you or AWS assigns to an AWS resource. Each tag consists of a key and a value. A key can have more than one value. You can use tags to organize your resources, and cost allocation tags to track your AWS costs on a detailed level.
- After you activate cost allocation tags, AWS uses the cost allocation tags to organize your resource costs on your cost allocation report, to make it easier for you to categorize and track your AWS costs.


CloudWatch
- You can publish your own metrics to CloudWatch using the AWS CLI or an API.
- Metrics are updated every five minutes and automatically collected and pushed to CloudWatch for every EMR cluster. This interval is not configurable. There is no charge for the Amazon EMR metrics reported in CloudWatch. Metrics are archived for two weeks, after which the data is discarded.
- You can aggregate your data before you publish to cloudwatch. When you have multiple data points per minute, aggregating data minimizes the number of calls to put-metric-data.
  for e.g. aws cloudwatch put-metric-data --metric-name PageViewCount --namespace MyService --statistic-value Sum=11,Minimum=2,Maximum=5 etc
- The metric you configure with CloudWatch for your Amazon SNS topics are automatically collected and pushed to CloudWatch every 5 minutes.
- In AWS documentation it is clearly mentioned that put-metric-data command has a limit of 8KB for GET and 40KB for POST requests.
- Available statics in CloudWatch
  => Average
  => Minimum
  => Maximum
  => Sum
  => Data Samples
- By default, there would always be network in, network out and CPU Utilization but teh DisRead (bytes) would remain 0.
- You can set custome bounds for the Y axis on a graph to help you see the data better. For eg, you can change the bounds on a CPUUtilization graph to 100 percent so that it's easy to see whether the CPU is low or high.
- You can switch between two different Y axes for your graph. This is particular useful if the graph contains metrics that have different units or that differ greatly in their range of values.
- 

CloudTrail
- AWS CloudTrail is the defacto service provided by AWS for monitoring all API calls to AWS and is used for logging and monitoring purposes for compliance. Amazon CloudTrail detects every call made to AWS and creates a log which can then be further used for analysis.

Service Limits
IAM 
- 1 user max 10 groups.
- 300 groups max per AWS account.
- 5000 IAM users per AWS account.
- 1000 roles per AWS account.
